{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable, List, Tuple, Any, Optional, Dict, Union, Callable\n",
    "import json \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import itertools\n",
    "from collections import defaultdict, Counter, OrderedDict\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "\n",
    "import datasets\n",
    "import qanom\n",
    "from qanom.annotations.common import read_annot_csv\n",
    "import qanom.evaluation.roles as qanom_roles # import SemanticRole, question_to_sem_role\n",
    "\n",
    "# Helper functions\n",
    "def report_overlap(**kwargs):\n",
    "    assert len(kwargs)==2\n",
    "    (nm1, s1), (nm2, s2) = tuple(kwargs.items())\n",
    "    s1, s2 = set(s1), set(s2)\n",
    "    print(f\"|{nm1}|={len(s1)}, |{nm2}|={len(s2)};   Union: {len(s1|s2)}  Intersection: {len(s1&s2)} \")\n",
    "    print(f\"|{nm1}-{nm2}|={len(s1-s2)}, |{nm2}-{nm1}|={len(s2-s1)};   \")\n",
    "\n",
    "def plot_counter_as_pie_chart(counter, title=None):\n",
    "    items = list(counter.items())\n",
    "    items = sorted(items, key=lambda kv: kv[0]) # sort by key\n",
    "    labels, sizes = zip(*items)\n",
    "\n",
    "    fig1, ax1 = plt.subplots()\n",
    "    ax1.pie(sizes, labels=labels, autopct='%1.1f%%',\n",
    "            shadow=True, startangle=90, textprops={\"color\":\"orange\"})\n",
    "    if title:\n",
    "        fig1.suptitle(title, fontsize=14, color=\"orange\")\n",
    "    \n",
    "\n",
    "def set_key_column(df, sent_id_lbl, pred_idx_lbl):\n",
    "    df['key'] = df.apply(lambda r: f\"{r[sent_id_lbl]}_{r[pred_idx_lbl]}\", axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: qanom/default\n",
      "Reusing dataset qanom (/home/nlp/kleinay/.cache/huggingface/datasets/biu-nlp___qanom/default/1.1.0/44d54349c6d3f70e326208bf63485003c5410d38a6aae87eb80d74cf887627d0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b46a4b19e2434eb980e938e6d2457002",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: qa_srl/plain_text\n",
      "Reusing dataset qa_srl (/home/nlp/kleinay/.cache/huggingface/datasets/kleinay___qa_srl/plain_text/1.0.0/9aaf099b628da9c576ebbc49bd242c93d0e6cc79ffdb2e0e1d3daf409f696820)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29218e04b27d40c09a1ee2bb48cd494a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Datasets\n",
    "qanom_dataset = datasets.load_dataset(\"biu-nlp/qanom\")\n",
    "qasrl_dataset = datasets.load_dataset(\"kleinay/qa_srl\")\n",
    "\n",
    "qanom_test_df = qanom_dataset['test'].to_pandas()\n",
    "qanom_dev_df = qanom_dataset['validation'].to_pandas()\n",
    "qasrl_dev_df = qasrl_dataset['validation'].to_pandas()\n",
    "qanom_train_df = qanom_dataset['train'].to_pandas()\n",
    "\n",
    "for df in (qanom_test_df, qanom_dev_df, qanom_train_df, qasrl_dev_df):\n",
    "    set_key_column(df, 'sent_id', 'predicate_idx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Argument Position Flexibility - verbs vs. nominals\n",
    "\n",
    "An interesting subject is argument order in verbs vs. nominals; \n",
    "This is part of analyzing why permutations help qanom and not qasrl - whether in is a matter of data-augmentation (qanom scarcity) or a matter of **more flexible argument position in nominals**.\n",
    "\n",
    "Here we first empirically check in qasrl and qanom data whether nominalizations have more \"flexible\" argument positions than verbs.\n",
    "\n",
    "We will quantify the variance of argument position for each Role (WH-word, conflating Who+What). \n",
    "To do that, we map every argument within an instance to an integer stating its relative position, where negative number indicate left of predicate and positive number indicate right of predicate. Then we compute variance of relative positions per Role. \n",
    "\n",
    "Total *flexibility* is computed as the weighted avreage of the variances of all roles (weighted by role frequency).\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nlp/kleinay/tmp/ipykernel_22394/1416594206.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['role'] = df.question.map(lambda a: a.item(0))\n",
      "/home/nlp/kleinay/tmp/ipykernel_22394/1416594206.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['role'] = df.role.map(lambda r: \"what-who\" if r in (\"what\", \"who\") else r)\n",
      "/home/nlp/kleinay/tmp/ipykernel_22394/1416594206.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['arg_idx'] = df.answer_ranges.map(get_position)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flexibility=2.1711872689262437\n",
      "variance of arg position per role:  OrderedDict([('how', 2.04507877843706), ('how long', 2.2186885704510977), ('how much', 2.1730341663990758), ('what-who', 2.1364742590779513), ('when', 2.509126170949904), ('where', 2.2836285616867835), ('why', 2.0863635102597624)])\n",
      "flexibility=2.619280126596887\n",
      "variance of arg position per role:  OrderedDict([('how', 2.4705889654883046), ('how long', 2.077819531114783), ('how much', 2.4024164119159215), ('what-who', 2.5963652010369778), ('when', 2.8215299427492924), ('where', 2.751353303164841), ('why', 2.5658670472860936)])\n",
      "variances (noms, verbs):\n",
      " [0.07400759036500482, 0.07587787094458415]\n",
      "Levenve test:  LeveneResult(statistic=18.918426914713965, pvalue=1.3822956657254566e-05)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def compute_position_variances(df):\n",
    "    df = df[df.question.str.len()>0]    # filter out non-QA rows\n",
    "    df['role'] = df.question.map(lambda a: a.item(0)) \n",
    "    df['role'] = df.role.map(lambda r: \"what-who\" if r in (\"what\", \"who\") else r)  \n",
    "    def get_position(ranges):\n",
    "        # if len(ranges)==0: return np.nan\n",
    "        span=min([tuple(sp) for sp in ranges])\n",
    "        return span[0]\n",
    "    df['arg_idx'] = df.answer_ranges.map(get_position) \n",
    "    df.loc[:, 'position'] = 0\n",
    "    # assign relative 'position' per argument (== row, QA; we take the first token in first answer span as position)\n",
    "    for key,df_pred in df.groupby('key'):\n",
    "        idxs = df_pred.arg_idx.to_numpy()\n",
    "        pred_idx: int = df_pred.predicate_idx.iloc[0]\n",
    "        # * First Approach: Ordered relative positions, w.r.t. predicate \n",
    "        # positive_positions = np.append(idxs, pred_idx).argsort()    # adding predicate_idx to argsort for setting it as anchor\n",
    "        # positions = (positive_positions - positive_positions[-1])[:-1] # predicate_idx position is 0, the rest are relative to it\n",
    "        # *** but this yield greater flexibility to qasrl, probably since it has higher variance of #-QAs . Trying another approach: **\n",
    "        # * Second Approach: taking relative position in fractions\n",
    "        positive_positions = idxs.argsort()\n",
    "        positions = (positive_positions + 1) / (max(positive_positions) + 1)\n",
    "        # * Third Approach: simple relative position (token distance from predicate)\n",
    "        # positions = idxs - pred_idx\n",
    "        \n",
    "        df.loc[df.key==key, 'position'] = positions \n",
    "    role2position_variance = OrderedDict()\n",
    "    role2position_mean = OrderedDict()\n",
    "    role2freq = OrderedDict()\n",
    "    # compute position variance per role\n",
    "    for role,df_role in df.groupby('role'):\n",
    "        # role2position_variance[role] = df_role.position.var()\n",
    "        # * Instead of taking variance, another option is to take the entropy of the relative position disribution (regarded as categorical).\n",
    "        # *  Higher entropy means position is closer to uniform, meaning higher variance and flexibility of argument position.\n",
    "        role2position_variance[role] = data_entropy(df_role.position)  \n",
    "        role2position_mean[role] = df_role.position.mean()\n",
    "        role2freq[role] = len(df_role)\n",
    "    # compute total flexibity \n",
    "    flexibility = np.average(list(role2position_variance.values()), weights=list(role2freq.values()))  \n",
    "    print(f\"flexibility={flexibility}\")  \n",
    "    print(\"variance of arg position per role: \", role2position_variance)\n",
    "    return df\n",
    "\n",
    "nom_df= compute_position_variances(qanom_dev_df)\n",
    "verb_df = compute_position_variances(qasrl_dev_df)\n",
    "print(\"variances (noms, verbs):\\n\", [np.var(df.position) for df in (nom_df, verb_df)])\n",
    "print(\"Levenve test: \", stats.levene(nom_df.position, verb_df.position, center='trimmed'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           [how, did, someone, say, something, _, _, ?]\n",
       "1                  [what, did, someone, say, _, _, _, ?]\n",
       "2          [when, did, someone, say, something, _, _, ?]\n",
       "3                  [who, _, _, said, something, _, _, ?]\n",
       "4           [why, did, someone, say, something, _, _, ?]\n",
       "                              ...                       \n",
       "2890            [what, should, _, continued, _, _, _, ?]\n",
       "2891    [when, should, something, continued, _, _, _, ?]\n",
       "2892     [why, should, something, continued, _, _, _, ?]\n",
       "2893      [what, is, _, attributed, _, to, something, ?]\n",
       "2894      [what, is, something, attributed, _, to, _, ?]\n",
       "Name: question, Length: 2895, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def data_entropy(lst: Iterable[Any], base=2):\n",
    "    ser = pd.Series(lst) if not isinstance(lst, pd.Series) else lst \n",
    "    p = ser.value_counts() / ser.sum()\n",
    "    return stats.entropy(p, base=base)\n",
    "\n",
    "df.question"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "efc159d1a32205ec9db73f14cd17171e4e15bf26729f2bc17d41c8a634b0d97c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 ('seq2seq-qasrl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
