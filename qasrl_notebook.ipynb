{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0013c89c-ed8a-4bc8-80fd-44e62536871b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Run one time on new server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e9e648-3eaf-4503-a5ba-554ef7d49000",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.qasrl_gs_utils import combine_files_tag_with_sentences\n",
    "\n",
    "combine_files_tag_with_sentences(\"qasrl_gs/data/gold/wikinews.dev.gold.csv\", \"qasrl_gs/data/sentences/wikinews.dev.full.csv\", \"qasrl_gs/data/gold/wikinews.dev.combined.csv\")\n",
    "combine_files_tag_with_sentences(\"qasrl_gs/data/gold/wikinews.test.gold.csv\", \"qasrl_gs/data/sentences/wikinews.test.full.csv\", \"qasrl_gs/data/gold/wikinews.test.combined.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d1edf2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c907b3-544d-4e43-bdc2-2e6e63c8bae7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Run on every notebook restart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb27079-5de3-4075-8072-6ace86846623",
   "metadata": {
    "autorun": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "from run_summarization import main\n",
    "from run_evaluation import evaluate\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "# General variables\n",
    "\n",
    "run = None  # wandb run\n",
    "tmp_dir = os.environ.get(\"TMPDIR\", \"/tmp\")\n",
    "\n",
    "# Params\n",
    "\n",
    "### Data params\n",
    "\n",
    "qasrl_2015_params = ['--dataset_name', 'qa_srl']\n",
    "qasrl_2020_params = [\n",
    "    \"--train_file\", \"qasrl_gs/data/gold/wikinews.dev.combined.csv\",\n",
    "    \"--validation_file\", \"qasrl_gs/data/gold/wikinews.dev.combined.csv\",\n",
    "    \"--test_file\", \"qasrl_gs/data/gold/wikinews.test.combined.csv\",\n",
    "    \"--text_column\", \"sentence\", \n",
    "    \"--summary_column\", \"answer\"\n",
    "]\n",
    "\n",
    "### Model params\n",
    "\n",
    "t5_model_dir = f'{tmp_dir}/t5-tst-summarization'\n",
    "os.environ[\"T5_MODEL_DIR\"] = t5_model_dir\n",
    "t5_small_model_train_params = [\n",
    "    '--model_name_or_path', 't5-small'\n",
    "]\n",
    "t5_model_predict_params = [\n",
    "    '--model_name_or_path', t5_model_dir\n",
    "]\n",
    "t5_extra_params = [\n",
    "    '--model_type', 't5',\n",
    "    '--source_prefix', 'summarize: ',\n",
    "    '--output_dir', t5_model_dir\n",
    "]\n",
    "\n",
    "bart_model_dir = f'{tmp_dir}/bart-tst-summarization'\n",
    "os.environ[\"BART_MODEL_DIR\"] = bart_model_dir\n",
    "bart_base_model_train_params = [\n",
    "    '--model_name_or_path', 'facebook/bart-base'\n",
    "]\n",
    "bart_model_predict_params = [\n",
    "    '--model_name_or_path', bart_model_dir\n",
    "]\n",
    "bart_extra_params = [\n",
    "    '--model_type', 'bart',\n",
    "    '--output_dir', bart_model_dir\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f028e8-c6e4-4b62-8e7c-499d93e75631",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Train, predict and evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e91ec00-901f-4a1f-9f2a-d41d740c5320",
   "metadata": {},
   "source": [
    "### (0) Run config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb24311-2d82-4b99-ba55-e3b3fb28e49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"bart\"\n",
    "# model_type = \"t5\"\n",
    "\n",
    "qasrl_train_dataset = \"2015\"\n",
    "# qasrl_train_dataset = \"2018\"\n",
    "\n",
    "# qasrl_test_dataset = \"2015\"\n",
    "qasrl_test_dataset = \"2020\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c539a5-20fd-49ad-8cc7-0418fb7cce32",
   "metadata": {},
   "source": [
    "### (1) Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2b3bdf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sys.argv = [\n",
    "    'run_summarization.py',\n",
    "    '--do_train',\n",
    "    '--do_eval',\n",
    "    '--per_device_train_batch_size', '4',\n",
    "    '--per_device_eval_batch_size', '4',\n",
    "    '--logging_steps', '100',\n",
    "    '--num_train_epochs', '3.0',\n",
    "    '--overwrite_output_dir',\n",
    "    '--report_to', 'wandb'    \n",
    "]\n",
    "\n",
    "if model_type == \"t5\":\n",
    "    sys.argv.extend(t5_small_model_train_params)\n",
    "    sys.argv.extend(t5_extra_params)\n",
    "elif model_type == \"bart\":\n",
    "    sys.argv.extend(bart_base_model_train_params)\n",
    "    sys.argv.extend(bart_extra_params)\n",
    "else:\n",
    "    raise ValueError(f\"model_type doesn't exist ; model_type {model_type}\")\n",
    "\n",
    "if qasrl_train_dataset == \"2015\":\n",
    "    sys.argv.extend(qasrl_2015_params)\n",
    "elif qasrl_train_dataset == \"2018\":\n",
    "    raise ValueError(\"qasrl_train_dataset 2018 not supported yet\")\n",
    "else:\n",
    "    raise ValueError(f\"qasrl_train_dataset doesn't exist ; qasrl_train_dataset {qasrl_train_dataset}\")\n",
    "\n",
    "_, run = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8040d99d-a9db-4650-a669-04c7ed155b14",
   "metadata": {},
   "source": [
    "### (2) Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25830f8-17dc-4b14-88a6-1e0bc32601a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !python run_summarization.py --model_name_or_path $TMPDIR/tst-summarization --do_predict --dataset_name qa_srl --output_dir $TMPDIR/tst-summarization --source_prefix \"summarize: \" --predict_with_generate\n",
    "sys.argv = [\n",
    "    'run_summarization.py',\n",
    "    '--do_predict',\n",
    "    '--predict_with_generate',\n",
    "    '--eval_accumulation_steps', '10',  # Necessary to avoid OOM where all predictions are kept on one GPU    \n",
    "    '--report_to', 'wandb',\n",
    "    '--wandb_run_name', run.name if run else None\n",
    "]\n",
    "\n",
    "if model_type == \"t5\":\n",
    "    sys.argv.extend(t5_extra_params)\n",
    "    sys.argv.extend(t5_model_predict_params)\n",
    "elif model_type == \"bart\":\n",
    "    sys.argv.extend(bart_extra_params)\n",
    "    sys.argv.extend(bart_model_predict_params)\n",
    "else:\n",
    "    raise ValueError(f\"model_type doesn't exist ; model_type {model_type}\")    \n",
    "\n",
    "if qasrl_test_dataset == \"2015\":\n",
    "    sys.argv.extend(qasrl_2015_params)\n",
    "elif qasrl_test_dataset == \"2020\":\n",
    "    sys.argv.extend(qasrl_2020_params)\n",
    "else:\n",
    "    raise ValueError(f\"qasrl_test_dataset doesn't exist ; qasrl_test_dataset {qasrl_test_dataset}\")\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566b812a-76d7-40bb-98fc-a82489b62ba1",
   "metadata": {},
   "source": [
    "### (3) Run state machine using docker, for parsing the predicted questions into 7 slot format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87686a8e-60f1-4c93-99f4-211045977251",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if model_type == \"t5\":\n",
    "    os.environ[\"MODEL_DIR\"] = t5_model_dir\n",
    "elif model_type == \"bart\":\n",
    "    os.environ[\"MODEL_DIR\"] = bart_model_dir\n",
    "else:\n",
    "    raise ValueError(f\"model_type doesn't exist ; model_type {model_type}\")    \n",
    "\n",
    "!docker run -it -v \"${MODEL_DIR}:/data\" -v \"$(pwd)/../qasrl_bart/qasrl_gs/data/sentences/:/sentences_data\" --rm --name qasrl hirscheran/qasrl_state_machine_example \"file\" \"/data/generated_predictions.csv\" \"/sentences_data/wikinews.test.full.csv\" \"/data/output_file.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4206c8-5789-46d3-9ba1-cb2b1b41e6e6",
   "metadata": {},
   "source": [
    "### (4) Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de20903-68d7-4f8b-b750-2990e1ba7f38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if model_type == \"t5\":\n",
    "    model_dir = t5_model_dir\n",
    "elif model_type == \"bart\":\n",
    "    model_dir = bart_model_dir\n",
    "else:\n",
    "    raise ValueError(f\"model_type doesn't exist ; model_type {model_type}\")    \n",
    "\n",
    "\n",
    "evaluate(\"qasrl_gs/data/gold/wikinews.test.gold.csv\", f\"{model_dir}/output_file.csv\", None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d341a7e-3cd4-45ed-ac42-49b528e0e633",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Run multiple experiments of train, predict and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d37e3b-be2f-4c21-b8d8-55dbf88be64f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# batch_size = 4\n",
    "# model_name_or_path = 't5-small'\n",
    "\n",
    "# # for batch_size in [4, 16]:\n",
    "# for model_params in [t5_small_model_params, bart_model_params]:\n",
    "# # for preprocess_output_func in ['all', 'first_two_question_answer']:\n",
    "#     sys.argv = [\n",
    "#         'run_summarization.py',\n",
    "#         '--do_train',\n",
    "#         '--do_eval',\n",
    "#         '--do_predict',\n",
    "#         '--predict_with_generate',\n",
    "#         '--do_predict_based_on_predictions_file',\n",
    "#         '--dataset_name', 'qa_srl',\n",
    "#         '--output_dir', f'{tmp_dir}/tst-summarization',\n",
    "#         '--per_device_train_batch_size', str(batch_size),\n",
    "#         '--per_device_eval_batch_size', str(batch_size),\n",
    "#         '--num_train_epochs', '3.0',\n",
    "#         '--overwrite_output_dir',\n",
    "#         '--eval_accumulation_steps', '10',  # Necessary to avoid OOM where all predictions are kept on one GPU\n",
    "#         '--report_to', 'wandb'    \n",
    "#     ]\n",
    "    \n",
    "#     sys.argv.extend(model_params)\n",
    "\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aed91c5-b6ad-4be6-a680-75e2e050f6eb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Debugging stuff (debug mode flag and more)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70982efa-1ebf-40e1-956c-93df5e754782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python run_summarization.py --model_name_or_path $TMPDIR/tst-summarization --do_predict --dataset_name qa_srl --output_dir $TMPDIR/tst-summarization --source_prefix \"summarize: \" --predict_with_generate --debug_mode\n",
    "sys.argv = [\n",
    "    'run_summarization.py',\n",
    "    '--model_name_or_path', f'{tmp_dir}/tst-summarization',\n",
    "    '--do_predict',\n",
    "    '--dataset_name', 'qa_srl',\n",
    "    '--output_dir', f'{tmp_dir}/tst-summarization',\n",
    "    '--source_prefix', 'summarize: ',\n",
    "    '--predict_with_generate',\n",
    "    '--eval_accumulation_steps', '10',  # Necessary to avoid OOM where all predictions are kept on one GPU        \n",
    "    '--debug_mode'\n",
    "]\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b4201a-c3b1-4219-b379-a28e0497f494",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open (\"/home/nlp/hirsche5/tmp/tst-summarization/generated_predictions.json\") as f:\n",
    "    predictions = json.loads(f.read())\n",
    "list(zip(predictions['inputs'], predictions['labels'], predictions['predictions']))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417dc49f-3eaa-4392-9235-b7ff5b6dbf14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !python run_summarization.py --model_name_or_path $TMPDIR/tst-summarization --do_predict_based_on_predictions_file --dataset_name qa_srl --output_dir $TMPDIR/tst-summarization --source_prefix \"summarize: \" --debug_mode --report_to \"wandb\"\n",
    "sys.argv = [\n",
    "    'run_summarization.py',\n",
    "    '--model_name_or_path', f'{tmp_dir}/tst-summarization',\n",
    "    '--do_predict_based_on_predictions_file',\n",
    "    '--dataset_name', 'qa_srl',\n",
    "    '--output_dir', f'{tmp_dir}/tst-summarization',\n",
    "    '--source_prefix', 'summarize: ',\n",
    "    '--debug_mode'\n",
    "]\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37f060c-9dca-489c-ab47-43bfdd508286",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
