{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05c82eb9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Run one time on new server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bd7c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare QASRL-GS (2020)\n",
    "from scripts.qasrl_gs_utils import combine_files_tag_with_sentences\n",
    "\n",
    "combine_files_tag_with_sentences(\"qasrl_gs/data/gold/wikinews.dev.gold.csv\", \"qasrl_gs/data/sentences/wikinews.dev.full.csv\", \"qasrl_gs/data/gold/wikinews.dev.combined.csv\")\n",
    "combine_files_tag_with_sentences(\"qasrl_gs/data/gold/wikinews.test.gold.csv\", \"qasrl_gs/data/sentences/wikinews.test.full.csv\", \"qasrl_gs/data/gold/wikinews.test.combined.csv\")\n",
    "combine_files_tag_with_sentences(\"qasrl_gs/data/gold/wikipedia.dev.gold.csv\", \"qasrl_gs/data/sentences/wikipedia.dev.full.csv\", \"qasrl_gs/data/gold/wikipedia.dev.combined.csv\")\n",
    "combine_files_tag_with_sentences(\"qasrl_gs/data/gold/wikipedia.test.gold.csv\", \"qasrl_gs/data/sentences/wikipedia.test.full.csv\", \"qasrl_gs/data/gold/wikipedia.test.combined.csv\")\n",
    "\n",
    "# Create full-data files od (combining wikipedia and wikinews domains)\n",
    "import pandas as pd\n",
    "dev_wikipedia_df = pd.read_csv(\"qasrl_gs/data/gold/wikipedia.dev.combined.csv\")\n",
    "dev_wikinews_df = pd.read_csv(\"qasrl_gs/data/gold/wikinews.dev.combined.csv\")\n",
    "test_wikipedia_df = pd.read_csv(\"qasrl_gs/data/gold/wikipedia.test.combined.csv\")\n",
    "test_wikinews_df = pd.read_csv(\"qasrl_gs/data/gold/wikinews.test.combined.csv\")\n",
    "dev_full = pd.concat((dev_wikipedia_df, dev_wikinews_df), axis='index')\n",
    "dev_full.to_csv(\"qasrl_gs/data/gold/all.dev.combined.csv\", index=False)\n",
    "test_full = pd.concat((test_wikipedia_df, test_wikinews_df), axis='index')\n",
    "test_full.to_csv(\"qasrl_gs/data/gold/all.test.combined.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e47f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare QANom dataset for evaluation\n",
    "!unzip QANom/qanom_dataset.zip -d QANom/dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df852734",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56b9042",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Run on every notebook restart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390244e8",
   "metadata": {
    "autorun": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Imports\n",
    "\n",
    "from run_parsing_model import main\n",
    "from evaluation import evaluate_qasrl, evaluate_qanom\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "# General variables\n",
    "\n",
    "run = None  # wandb run\n",
    "# tmp_dir = os.environ.get(\"TMPDIR\", \"/tmp\")\n",
    "tmp_dir = os.environ.get(\"HOME\") + \"/tmp\"\n",
    "\n",
    "# Params\n",
    "\n",
    "### Data params\n",
    "\n",
    "qasrl_2015_params = ['--dataset_name', 'qa_srl']\n",
    "qasrl_2018_params = ['--dataset_name', 'biu-nlp/qa_srl2018']\n",
    "qasrl_2020_params = ['--dataset_name', 'biu-nlp/qa_srl2020'\n",
    "    # \"--train_file\", \"qasrl_gs/data/gold/wikinews.dev.combined.csv\",\n",
    "    # \"--validation_file\", \"qasrl_gs/data/gold/all.dev.combined.csv\",\n",
    "    # \"--test_file\", \"qasrl_gs/data/gold/all.test.combined.csv\",\n",
    "    \"--text_column\", \"sentence\", \n",
    "    \"--summary_column\", \"answer\"\n",
    "]\n",
    "qanom_params = ['--dataset_name', 'biu-nlp/qanom']  \n",
    "\n",
    "### Model params\n",
    "\n",
    "t5_model_dir = f'{tmp_dir}/t5-tst-summarization'\n",
    "os.environ[\"T5_MODEL_DIR\"] = t5_model_dir\n",
    "t5_small_model_train_params = [\n",
    "    '--model_name_or_path', 't5-small'\n",
    "]\n",
    "t5_model_predict_params = [\n",
    "    '--model_name_or_path', t5_model_dir\n",
    "]\n",
    "t5_extra_params = [\n",
    "    '--model_type', 't5',\n",
    "    '--source_prefix', 'summarize: ',\n",
    "    '--output_dir', t5_model_dir\n",
    "]\n",
    "\n",
    "bart_model_dir = f'{tmp_dir}/bart-tst-summarization'\n",
    "os.environ[\"BART_MODEL_DIR\"] = bart_model_dir\n",
    "bart_base_model_train_params = [\n",
    "    '--model_name_or_path', 'facebook/bart-base'\n",
    "]\n",
    "bart_model_predict_params = [\n",
    "    '--model_name_or_path', bart_model_dir\n",
    "]\n",
    "bart_extra_params = [\n",
    "    '--model_type', 'bart',\n",
    "    '--output_dir', bart_model_dir\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef45c210",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0193f5d1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Train, predict and evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1db77a5",
   "metadata": {},
   "source": [
    "### (0) Run config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b50a3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_type = \"bart\"\n",
    "model_type = \"t5\"\n",
    "\n",
    "# qasrl_train_dataset = \"2015\"\n",
    "# qasrl_train_dataset = \"2018\"\n",
    "qasrl_train_dataset = \"qanom\"\n",
    "\n",
    "# qasrl_test_dataset = \"2015\"\n",
    "# qasrl_test_dataset = \"2020\"\n",
    "qasrl_test_dataset = \"qanom\"\n",
    "\n",
    "train_epochs = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edb268f",
   "metadata": {},
   "source": [
    "### (1) Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4f647a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "sys.argv = [\n",
    "    'run_parsing_model.py',\n",
    "    '--do_train',\n",
    "    '--do_eval',\n",
    "    '--per_device_train_batch_size', '12',\n",
    "    '--per_device_eval_batch_size', '12',\n",
    "    '--logging_steps', '200',\n",
    "    '--num_train_epochs', f'{train_epochs}',\n",
    "    '--report_to', 'wandb',\n",
    "    \n",
    "    '--preprocess_output_func', 'all_by_answer_ordering', # Order output-QAs by indices\n",
    "\n",
    "    # '--overwrite_output_dir', # removing this will load and finetune the last checkpoint from output_dir automatically\n",
    "    # '--resume_from_checkpoint', 'path-to-checkpoint' # Specifying a checkpoint to load and finetune  \n",
    "    \n",
    "    # '--n_gpu', '[5,6]'\n",
    "]\n",
    "\n",
    "if model_type == \"t5\":\n",
    "    sys.argv.extend(t5_small_model_train_params)\n",
    "    sys.argv.extend(t5_extra_params)\n",
    "    model_dir = t5_model_dir\n",
    "elif model_type == \"bart\":\n",
    "    sys.argv.extend(bart_base_model_train_params)\n",
    "    sys.argv.extend(bart_extra_params)\n",
    "    model_dir = bart_model_dir\n",
    "else:\n",
    "    raise ValueError(f\"model_type doesn't exist ; model_type {model_type}\")\n",
    "\n",
    "if qasrl_train_dataset == \"2015\":\n",
    "    sys.argv.extend(qasrl_2015_params)\n",
    "elif qasrl_train_dataset == \"2018\":\n",
    "    sys.argv.extend(qasrl_2018_params)\n",
    "elif qasrl_train_dataset == \"qanom\":\n",
    "    sys.argv.extend(qanom_params)\n",
    "else:\n",
    "    raise ValueError(f\"qasrl_train_dataset doesn't exist ; qasrl_train_dataset {qasrl_train_dataset}\")\n",
    "\n",
    "_, run = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b6ef66",
   "metadata": {},
   "source": [
    "### (2) Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db757ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# !python run_parsing_model.py --model_name_or_path $TMPDIR/tst-summarization --do_predict --dataset_name qa_srl --output_dir $TMPDIR/tst-summarization --source_prefix \"summarize: \" --predict_with_generate\n",
    "sys.argv = [\n",
    "    'run_parsing_model.py',\n",
    "    '--do_predict',\n",
    "    '--predict_with_generate',\n",
    "    '--eval_accumulation_steps', '10',  # Necessary to avoid OOM where all predictions are kept on one GPU    \n",
    "    '--report_to', 'wandb',\n",
    "    '--wandb_run_name', run.name if run else None,\n",
    "    '--preprocess_output_func', 'all_by_answer_ordering' # Order output-QAs by indices\n",
    "]\n",
    "\n",
    "if model_type == \"t5\":\n",
    "    sys.argv.extend(t5_extra_params)\n",
    "    sys.argv.extend(t5_model_predict_params)\n",
    "elif model_type == \"bart\":\n",
    "    sys.argv.extend(bart_extra_params)\n",
    "    sys.argv.extend(bart_model_predict_params)\n",
    "else:\n",
    "    raise ValueError(f\"model_type doesn't exist ; model_type {model_type}\")    \n",
    "\n",
    "if qasrl_test_dataset == \"2015\":\n",
    "    sys.argv.extend(qasrl_2015_params)\n",
    "elif qasrl_test_dataset == \"2020\":\n",
    "    sys.argv.extend(qasrl_2020_params)\n",
    "    test_sentences_path = \"/sentences_data/wikinews.test.full.csv\"\n",
    "elif qasrl_test_dataset == \"qanom\":\n",
    "    sys.argv.extend(qanom_params)\n",
    "    test_sentences_path = \"/data/generated_predictions.csv\" # generated predictions will also hold a \"tokens\" columns and could serve as sentences-file   \n",
    "else:\n",
    "    raise ValueError(f\"qasrl_test_dataset doesn't exist ; qasrl_test_dataset {qasrl_test_dataset}\")\n",
    "\n",
    "main(generate_sentence_column_in_prediction= qasrl_test_dataset == \"qanom\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1541d8eb",
   "metadata": {},
   "source": [
    "### (3) Run state machine using docker, for parsing the predicted questions into 7 slot format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f867d175",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import run_parsing_model, strings_to_objects_parser\n",
    "reload(run_parsing_model)\n",
    "reload(strings_to_objects_parser)\n",
    "\n",
    "from run_parsing_model import main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4c9369",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"MODEL_DIR\"] = model_dir \n",
    "if qasrl_test_dataset != \"qanom\":\n",
    "    !docker run -it -v \"${MODEL_DIR}:/data\" -v \"$(pwd)/../qasrl_bart/qasrl_gs/data/sentences/:/sentences_data\" --rm --name qasrl-automaton hirscheran/qasrl_state_machine_example \"file\" \"/data/generated_predictions.csv\" \"$test_sentences_path\" \"/data/state_machine_output.csv\" > /dev/null 2>&1\n",
    "else:\n",
    "    !docker run -it -v \"${MODEL_DIR}:/data\" --rm --name qasrl-automaton hirscheran/qasrl_state_machine_example \"file\" \"/data/generated_predictions.csv\" \"/data/state_machine_output.csv\" > /dev/null 2>&1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17405062",
   "metadata": {},
   "source": [
    "### (4) Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53487493",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if qasrl_test_dataset != \"qanom\":\n",
    "    evaluate_qasrl(\"qasrl_gs/data/gold/wikinews.test.gold.csv\", f\"{model_dir}/output_file.csv\", None, None)\n",
    "else:\n",
    "    evaluate_qanom(model_dir, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5b6ef5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Run multiple experiments of train, predict and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce2f99b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# batch_size = 4\n",
    "# model_name_or_path = 't5-small'\n",
    "\n",
    "# # for batch_size in [4, 16]:\n",
    "# for model_params in [t5_small_model_params, bart_model_params]:\n",
    "# # for preprocess_output_func in ['all', 'first_two_question_answer']:\n",
    "#     sys.argv = [\n",
    "#         'run_parsing_model.py',\n",
    "#         '--do_train',\n",
    "#         '--do_eval',\n",
    "#         '--do_predict',\n",
    "#         '--predict_with_generate',\n",
    "#         '--do_predict_based_on_predictions_file',\n",
    "#         '--dataset_name', 'qa_srl',\n",
    "#         '--output_dir', f'{tmp_dir}/tst-summarization',\n",
    "#         '--per_device_train_batch_size', str(batch_size),\n",
    "#         '--per_device_eval_batch_size', str(batch_size),\n",
    "#         '--num_train_epochs', '3.0',\n",
    "#         '--overwrite_output_dir',\n",
    "#         '--eval_accumulation_steps', '10',  # Necessary to avoid OOM where all predictions are kept on one GPU\n",
    "#         '--report_to', 'wandb'    \n",
    "#     ]\n",
    "    \n",
    "#     sys.argv.extend(model_params)\n",
    "\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabe9dff",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Debugging stuff (debug mode flag and more)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c13bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python run_parsing_model.py --model_name_or_path $TMPDIR/tst-summarization --do_predict --dataset_name qa_srl --output_dir $TMPDIR/tst-summarization --source_prefix \"summarize: \" --predict_with_generate --debug_mode\n",
    "sys.argv = [\n",
    "    'run_parsing_model.py',\n",
    "    '--model_name_or_path', f'{tmp_dir}/tst-summarization',\n",
    "    '--do_predict',\n",
    "    '--dataset_name', 'qa_srl',\n",
    "    '--output_dir', f'{tmp_dir}/tst-summarization',\n",
    "    '--source_prefix', 'summarize: ',\n",
    "    '--predict_with_generate',\n",
    "    '--eval_accumulation_steps', '10',  # Necessary to avoid OOM where all predictions are kept on one GPU        \n",
    "    '--debug_mode'\n",
    "]\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69f6384",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open (\"/home/nlp/hirsche5/tmp/tst-summarization/generated_predictions.json\") as f:\n",
    "    predictions = json.loads(f.read())\n",
    "list(zip(predictions['inputs'], predictions['labels'], predictions['predictions']))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d57ac64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !python run_parsing_model.py --model_name_or_path $TMPDIR/tst-summarization --do_predict_based_on_predictions_file --dataset_name qa_srl --output_dir $TMPDIR/tst-summarization --source_prefix \"summarize: \" --debug_mode --report_to \"wandb\"\n",
    "sys.argv = [\n",
    "    'run_parsing_model.py',\n",
    "    '--model_name_or_path', f'{tmp_dir}/tst-summarization',\n",
    "    '--do_predict_based_on_predictions_file',\n",
    "    '--dataset_name', 'qa_srl',\n",
    "    '--output_dir', f'{tmp_dir}/tst-summarization',\n",
    "    '--source_prefix', 'summarize: ',\n",
    "    '--debug_mode'\n",
    "]\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42feb3f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "efc159d1a32205ec9db73f14cd17171e4e15bf26729f2bc17d41c8a634b0d97c"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
